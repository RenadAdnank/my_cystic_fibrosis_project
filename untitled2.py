# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sZvFB-6b-Z8MnXiqFCUa_PnRLt4XhKrf
"""

from google.colab import files
uploaded = files.upload()

import os
import zipfile

# إنشاء مجلد مخفي .kaggle
os.makedirs("/root/.kaggle", exist_ok=True)

# نقل ملف kaggle.json إليه
with open("/root/.kaggle/kaggle.json", "w") as f:
    # The following lines need to be indented to be part of the 'with' block
    filename = list(uploaded.keys())[0]
    f.write(uploaded[filename].decode())
# تعيين صلاحيات الملف
os.chmod("/root/.kaggle/kaggle.json", 600)

!kaggle datasets download -d ukveteran/cystic-fibrosis-data

with zipfile.ZipFile("cystic-fibrosis-data.zip", 'r') as zip_ref:
    zip_ref.extractall("cf_data")

files = os.listdir("cf_data")
files

import pandas as pd
df = pd.read_csv("cf_data/cf.csv")
df.head()

if 'Unnamed: 0' in df.columns:
    df = df.drop(columns=["Unnamed: 0"])
else:
    print("Column 'Unnamed: 0' not found in DataFrame.")

num_attributes = df.shape[1] - 1
print("Number of attributes:", num_attributes)

print("Number of samples:",df.shape[0])

df.describe()

df.isnull().sum().sum()

import matplotlib.pyplot as plt

df.hist(figsize=(15, 12), bins=3)
plt.tight_layout()
plt.show()

import seaborn as sns

sns.countplot(data=df, x='y')
plt.title("Target Class Distribution")
plt.show()

import numpy as np

plt.figure(figsize=(12, 10))
sns.heatmap(df.corr(), annot=False, cmap="coolwarm")
plt.title("Feature Correlation Heatmap")
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
sns.boxplot(data=df)
plt.title("Boxplot of All Features")
plt.xticks(rotation=90)
plt.show()

from sklearn.preprocessing import StandardScaler
X = df.drop(columns=['y'])
y = df['y']
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

pd.DataFrame(X_scaled, columns=X.columns).head()

import pandas as pd
from sklearn.model_selection import train_test_split

# Load the data
data = pd.read_csv('cf_data/cf.csv')

# Split the data into features (X) and target (y)
X = data.drop('y', axis=1)  # Features
y = data['y']  # Target values

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Save the split data into CSV files
X_train.to_csv('X_train.csv', index=False)
X_test.to_csv('X_test.csv', index=False)
y_train.to_csv('y_train.csv', index=False)
y_test.to_csv('y_test.csv', index=False)

print("Data has been successfully split and saved.")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score


# Replace 'target_column_name' with 'y' which is the actual name of the target column
X = df.drop(columns=['y'])
y = df['y']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


models = {
    "Logistic Regression": LogisticRegression(),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Support Vector Machine": SVC(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier()
}


results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    acc = accuracy_score(y_test, predictions)
    results[name] = acc
    print(f"{name}: Accuracy = {acc:.2f}")

best_model = max(results, key=results.get)
worst_model = min(results, key=results.get)

print(f"\nBest Performing Model: {best_model} with accuracy {results[best_model]:.2f}")
print(f"Worst Performing Model: {worst_model} with accuracy {results[worst_model]:.2f}")

results_df = pd.DataFrame(list(results.items()), columns=["Model", "Accuracy"])
print(results_df)

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.bar(results_df['Model'], results_df['Accuracy'], color='skyblue')
plt.title('Model Accuracy Comparison')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt


results_df = pd.DataFrame(list(results.items()), columns=["Model", "Accuracy"])
plt.figure(figsize=(10, 6))
sns.set(style="whitegrid")

barplot = sns.barplot(x="Accuracy", y="Model", data=results_df, palette="viridis", edgecolor=".2")


for i in barplot.containers:
    barplot.bar_label(i, fmt='%.2f', label_type='edge', padding=3)

plt.title("Comparison of Model Accuracies", fontsize=16)
plt.xlabel("Accuracy")
plt.ylabel("Model")
plt.xlim(0, 1)
plt.tight_layout()
plt.show()

# استيراد المكتبات

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

# 1. تحميل البيانات
def load_data():
    # Update the path to your actual data file
    original_data = pd.read_csv('cf_data/cf.csv')  # Changed path here to 'cf_data/cf.csv'
    return original_data

# 2. معالجة البيانات
def preprocess_data(data):
    processed_data = data.dropna()
    return processed_data

# 3. بناء النموذج
def build_model():
    model = RandomForestClassifier()
    return model

# 4. تدريب النموذج
def train_model(model, X_train, y_train):
    model.fit(X_train, y_train)
    return model

# 5. تقييم النموذج
def evaluate_model(model, X_test, y_test):
    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    return accuracy

# 6. الحصول على التوقعات
def get_predictions(model, X):
    predictions = model.predict(X)
    return predictions

# 7. حفظ النتائج
def save_predictions(predictions, filename):
    pd.DataFrame(predictions).to_csv(filename, index=False)

# 8. تنفيذ جميع الخطوات
def main():
    data = load_data()
    processed_data = preprocess_data(data)

    # Assuming 'y' is your target column, update if different
    X = processed_data.drop('y', axis=1)  # Changed 'target' to 'y'
    y = processed_data['y']           # Changed 'target' to 'y'

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = build_model()
    trained_model = train_model(model, X_train, y_train)

    accuracy = evaluate_model(trained_model, X_test, y_test)
    print(f"Model accuracy: {accuracy}")

    predictions = get_predictions(trained_model, X_test)
    save_predictions(predictions, 'predictions_RF_model.csv')

# تشغيل البرنامج
main()

from google.colab import files
files.download('cf_data/cf.csv')

from google.colab import files
files.download('y_train.csv')

import os

for root, dirs, files in os.walk('/content'):
    for file in files:
        if 'predictions_RF_model.csv' in file:
            print(os.path.join(root, file))

from google.colab import files
files.download('/content/predictions_RF_model.csv')

import os

# عرض محتويات المجلد الحالي
print(os.listdir())

# إذا كان الملف في مجلد اسمه "Results"
if os.path.exists("Results"):
    print("محتويات مجلد Results:")
    print(os.listdir("Results"))

import pandas as pd
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


# Load your data (replace with your actual data loading)
data = pd.read_csv('cf_data/cf.csv')  # Assuming your data is in 'cf_data/cf.csv'
X = data.drop('y', axis=1)
y = data['y']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Create and train the SVM model
svm_model = SVC()
svm_model.fit(X_train, y_train)

# Get predictions
predictions_svm = svm_model.predict(X_test) # predictions_svm is assigned here

# Save predictions
import os
os.makedirs("Results", exist_ok=True)
pd.DataFrame(predictions_svm, columns=["Prediction"]).to_csv("Results/predictions_SVM_model.csv", index=False)

from google.colab import files
files.download("Results/predictions_SVM_model.csv")